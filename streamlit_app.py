# streamlit_app.py
import streamlit as st
import json
from dotenv import load_dotenv
import logging
import atexit # Pour le nettoyage

# Importer les composants cl√©s de votre agent existant
from main_api_agent import app as langgraph_app
from main_api_agent import MainAgentGraphState
from langchain_core.messages import HumanMessage, AIMessage

from tools.limesurvey_api_client import get_session_key_api, release_session_key_api

# Configuration du logging
log_format = '%(asctime)s - %(name)s - %(levelname)s - %(module)s.%(funcName)s:%(lineno)d - %(message)s'
# Streamlit a son propre logger, donc on configure le logger racine pour nos modules.
# Pour voir les logs dans la console o√π Streamlit est lanc√©:
logging.basicConfig(level=logging.INFO, format=log_format, handlers=[logging.StreamHandler()])
logger = logging.getLogger(__name__) # Logger sp√©cifique √† ce fichier Streamlit

# Charger les variables d'environnement
if load_dotenv():
    logger.info(".env file loaded by Streamlit app.")
else:
    logger.warning(".env file not found. Ensure API keys and other configs are in environment.")


# --- Configuration de la Page Streamlit ---
st.set_page_config(page_title="Assistant IA LimeSurvey", layout="wide")
st.title("ü§ñ Assistant IA pour l'exploration des donn√©es LimeSurvey")
st.caption("Posez des questions en langage naturel sur vos enqu√™tes LimeSurvey.")

# --- Gestion de l'√âtat de Session Streamlit ---
if "messages" not in st.session_state:
    st.session_state.messages = [] # Historique des messages de la conversation actuelle
    logger.info("Historique des messages Streamlit initialis√©.")

if "limesurvey_session_key" not in st.session_state:
    st.session_state.limesurvey_session_key = None
    logger.info("Cl√© de session LimeSurvey dans Streamlit initialis√©e √† None.")

# --- Initialisation de la Session API LimeSurvey (une seule fois par session Streamlit) ---
if st.session_state.limesurvey_session_key is None:
    logger.info("Tentative d'obtention de la cl√© de session LimeSurvey pour la session Streamlit...")
    with st.spinner("Connexion √† l'API LimeSurvey..."):
        try:
            key = get_session_key_api()
            if key:
                st.session_state.limesurvey_session_key = key
                logger.info(f"Cl√© de session LimeSurvey obtenue : {key[:10]}...")
                # st.sidebar.success("Connect√© √† l'API LimeSurvey.") # Optionnel, si vous utilisez une sidebar
            else:
                error_message = "√âchec de l'obtention de la cl√© de session LimeSurvey. V√©rifiez les logs du client API."
                logger.error(error_message)
                st.error(error_message + " L'application ne peut pas continuer.")
                st.stop() 
        except Exception as e:
            error_message = f"Erreur critique lors de la connexion √† LimeSurvey : {str(e)}"
            logger.critical(error_message, exc_info=True)
            st.error(error_message + " L'application ne peut pas continuer.")
            st.stop()

# --- Nettoyage de la session API √† la fin de l'ex√©cution du script ---
# Cela ne fonctionne que lorsque le script Python s'arr√™te,
# pas n√©cessairement quand l'utilisateur ferme l'onglet.
def cleanup_limesurvey_session_on_exit():
    if st.session_state.get("limesurvey_session_key"): # Utiliser .get pour √©viter KeyError si non d√©fini
        logger.info("Nettoyage atexit : Lib√©ration de la cl√© de session LimeSurvey...")
        release_session_key_api()
        st.session_state.limesurvey_session_key = None # Mettre √† None dans l'√©tat de session
        logger.info("Cl√© de session LimeSurvey lib√©r√©e (atexit).")

if "atexit_registered" not in st.session_state:
    atexit.register(cleanup_limesurvey_session_on_exit)
    st.session_state.atexit_registered = True
    logger.info("Fonction de nettoyage atexit enregistr√©e.")


# --- Affichage de l'Historique des Messages ---
for msg_idx, message_obj in enumerate(st.session_state.messages):
    role = "user" if message_obj.type == "human" else "assistant"
    with st.chat_message(role, avatar="üßë‚Äçüíª" if role == "user" else "ü§ñ"):
        content_to_display = message_obj.content
        if content_to_display:
             st.markdown(content_to_display)


# --- Champ de Saisie Utilisateur et Logique d'Appel de l'Agent ---
if user_prompt := st.chat_input("Posez votre question ici..."):
    logger.info(f"Requ√™te utilisateur re√ßue: '{user_prompt}'")
    
    # Ajouter le message utilisateur √† l'historique Streamlit et l'afficher
    st.session_state.messages.append(HumanMessage(content=user_prompt))
    with st.chat_message("user", avatar="üßë‚Äçüíª"):
        st.markdown(user_prompt)

    # Pr√©parer l'√©tat pour l'appel au graphe LangGraph
    # L'historique complet (st.session_state.messages) est pass√©.
    graph_input_state = MainAgentGraphState(
        user_query=user_prompt,
        messages=st.session_state.messages, # Contient d√©j√† le dernier HumanMessage
        final_output=None
    )
    
    logger.debug(f"√âtat initial pour LangGraph: {graph_input_state}")

    # Afficher un message "en cours de traitement" et appeler l'agent
    with st.chat_message("assistant", avatar="ü§ñ"):
        message_placeholder = st.empty() # Pour afficher les "pens√©es" ou la r√©ponse finale
        with st.spinner("L'agent IA r√©fl√©chit et consulte les donn√©es..."):
            try:
                # Invoquer le graphe LangGraph
                # La configuration de r√©cursion est pour le graphe lui-m√™me, pas pour l'AgentExecutor.
                # Note: `app.stream()` pourrait √™tre utilis√© ici pour des mises √† jour en temps r√©el des √©tapes de l'agent,
                # mais cela n√©cessite une gestion plus complexe de l'affichage des ToolMessages.
                # Pour l'instant, `invoke` est plus simple pour obtenir la r√©ponse finale.
                
                logger.info("Invocation de LangGraph app...")
                final_graph_state_result = langgraph_app.invoke(graph_input_state, config={"recursion_limit": 15})
                logger.info(f"R√©sultat de LangGraph app: {str(final_graph_state_result)[:500]}...")

                if final_graph_state_result and "final_output" in final_graph_state_result:
                    ai_response_content = final_graph_state_result["final_output"]
                    if not ai_response_content: # Si final_output est vide
                         ai_response_content = "L'agent n'a pas produit de r√©ponse textuelle explicite mais a peut-√™tre termin√© ses actions."
                else:
                    ai_response_content = "L'agent n'a pas retourn√© de sortie dans le format attendu."
                    logger.error(f"Structure de r√©ponse inattendue de LangGraph: {final_graph_state_result}")

            except Exception as e:
                logger.error(f"Erreur critique lors de l'invocation de LangGraph: {e}", exc_info=True)
                ai_response_content = f"D√©sol√©, une erreur technique est survenue lors du traitement de votre demande : {str(e)}"
        
        # Afficher la r√©ponse de l'IA
        message_placeholder.markdown(ai_response_content)

    # Ajouter la r√©ponse de l'IA √† l'historique Streamlit
    st.session_state.messages.append(AIMessage(content=ai_response_content))
    logger.info("R√©ponse de l'IA ajout√©e √† l'historique Streamlit.")

# Optionnel : Bouton pour r√©initialiser la conversation
if st.sidebar.button("R√©initialiser la conversation"):
    st.session_state.messages = []
    logger.info("Historique de conversation Streamlit r√©initialis√© par l'utilisateur.")
    # La cl√© de session LimeSurvey N'EST PAS r√©initialis√©e ici, elle reste active pour la session Streamlit.
    st.rerun()

st.sidebar.info("Cette application utilise un agent IA pour interroger l'API LimeSurvey. Les logs de l'agent (y compris les appels d'outils) sont visibles dans la console o√π Streamlit est lanc√©.")